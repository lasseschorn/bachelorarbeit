{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "import variablen as var\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import linear_model\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "methode = var.methode_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = var.result_dir + methode + \"/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mar_files = os.listdir(var.mar_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcar_files = os.listdir(var.mcar_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnar_files = os.listdir(var.mnar_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_original  = pd.read_csv(var.prepaired_df, delimiter=\";\", decimal=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation(dataset, column):\n",
    "    threshold = -1\n",
    "    col_corr = \"\"\n",
    "    corr_matrix = dataset.corr()\n",
    "    for i in range(len(corr_matrix.columns)):\n",
    "        for j in range(i):\n",
    "            if corr_matrix.iloc[i, j] > threshold and corr_matrix.iloc[i, j] != 1 and corr_matrix.columns[j] == column :\n",
    "                threshold = corr_matrix.iloc[i, j]\n",
    "                col_corr = corr_matrix.columns[i]\n",
    "    return col_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imputation(df,column,col_corr):\n",
    "    s = df[col_corr].drop_duplicates()\n",
    "    for i, v in s.items():\n",
    "        if pd.isna(v):\n",
    "            new_df = df[df[col_corr].isna()]\n",
    "        else:\n",
    "            new_df = df[df[col_corr] == v ]\n",
    "        #Mode gibt eine Serie's wieder     \n",
    "        new_df[column].fillna(new_df[column].mode().iloc[0], inplace=True)     \n",
    "        df.update(new_df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute(file,column,col_corr):\n",
    "    df = pd.read_csv(file, delimiter=\";\", decimal=\",\")\n",
    "    result = imputation(df,column,col_corr) \n",
    "    #result.to_csv( save_dir  + 'MAR/' + \"test_\" + column + '.csv'  ,index=False,sep=';', decimal=',')\n",
    "    return result[column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\GreenBook\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\GreenBook\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.0\n",
      "14.0\n",
      "4.0\n",
      "14.0\n",
      "14.0\n",
      "14.0\n",
      "4.0\n",
      "20.0\n",
      "4.0\n",
      "15.0\n",
      "60.0\n",
      "33.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\GreenBook\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "for column in var.columns:\n",
    "    results = df_original[[column]].copy()\n",
    "    col_corr = correlation(df_original, column)\n",
    "    for i in mar_files:\n",
    "        results[i[0:-4]] = execute(var.mar_dir + i, column,col_corr )\n",
    "    results.to_csv( save_dir  + 'MAR/' + column + '.csv'  ,index=False,sep=';', decimal=',')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in var.columns:\n",
    "    results = df_original[[column]].copy()\n",
    "    for i in mcar_files:\n",
    "        results[i[0:-4]] = execute(var.mcar_dir + i, column)\n",
    "    results.to_csv( save_dir  + 'MCAR/' + column + '.csv'  ,index=False,sep=';', decimal=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       AMT_INCOME_TOTAL\n",
      "count     438557.000000\n",
      "mean          27.432537\n",
      "std           58.753444\n",
      "min            0.000000\n",
      "25%            6.000000\n",
      "50%           14.000000\n",
      "75%           25.000000\n",
      "max          865.000000\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "execute() missing 1 required positional argument: 'col_corr'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-1bb6f42fb96b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_original\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmnar_files\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m         \u001b[0mresults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmnar_dir\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mresults\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0msave_dir\u001b[0m  \u001b[1;33m+\u001b[0m \u001b[1;34m'MNAR/'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mcolumn\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'.csv'\u001b[0m  \u001b[1;33m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m';'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecimal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m','\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: execute() missing 1 required positional argument: 'col_corr'"
     ]
    }
   ],
   "source": [
    "for column in var.columns:\n",
    "    print(df_original[[column]].describe())\n",
    "    results = df_original[[column]].copy()\n",
    "    for i in mnar_files:\n",
    "        results[i[0:-4]] = execute(var.mnar_dir + i, column)\n",
    "    results.to_csv( save_dir  + 'MNAR/' + column + '.csv'  ,index=False,sep=';', decimal=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FÃ¼r Test der Modus\n",
    "def imputation(df,column,col_corr):\n",
    "    result = df_original[[column,col_corr]]\n",
    "    result['col_corr'] = df[col_corr]\n",
    "    result['vorher'] = df[column]\n",
    "    s = df[col_corr].drop_duplicates()\n",
    "    for i, v in s.items():\n",
    "        if pd.isna(v):\n",
    "            new_df = df[df[col_corr].isna()]\n",
    "        else:\n",
    "            new_df = df[df[col_corr] == v ]\n",
    "        temp = new_df[column].mode()\n",
    "        print(new_df[column].mode().iloc[0] )\n",
    "        print(new_df[column].median() )\n",
    "        #new_df[column].fillna(new_df[column].median(), inplace=True) \n",
    "        new_df[column].fillna(new_df[column].mode().iloc[0], inplace=True)\n",
    "        df.update(new_df)    \n",
    "    result['nachher'] = df[column]\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FÃ¼r test der Modus\n",
    "def execute(file,column,col_corr):\n",
    "    df = pd.read_csv(file, delimiter=\";\", decimal=\",\")\n",
    "    result = imputation(df,column,col_corr) \n",
    "    result.to_csv( save_dir  + 'MAR/' + \"test_\" + column + '.csv'  ,index=True,sep=';', decimal=',')\n",
    "    return result['nachher']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imputation(df,column,col_corr):\n",
    "    result = df_original[[column,col_corr]]\n",
    "    result['col_corr'] = df[col_corr]\n",
    "    result['vorher'] = df[column]\n",
    "    s = df[col_corr].drop_duplicates()\n",
    "    print(s)\n",
    "    for i, v in s.items():\n",
    "        #print(col_corr)\n",
    "        \n",
    "        temp = df[df[col_corr] == v][column].dropna()\n",
    "        med = temp.median()\n",
    "        new_df = df[df[col_corr] == v ]\n",
    "        print(med)\n",
    "        print(\"BEFORE FILLING\")\n",
    "        print(new_df.iloc[:, 4:7].head())\n",
    "\n",
    " \n",
    "\n",
    "        print(\"----------------------------------------------------------\")\n",
    "        print(\"AFTER FILLING\")\n",
    "        new_df.fillna(med, inplace=True)\n",
    "        print(new_df.iloc[:, 4:7].head())\n",
    "        index = new_df.index\n",
    "        new_df.to_csv( save_dir  + 'MAR/' + \"test_\" + str(v) +\"_\" + column + '.csv'  ,index=True,sep=';', decimal=',')\n",
    "        print(\"----------------------------------------------------------\")\n",
    "        print(\"RESULT BEFORE\")\n",
    "        print(df.iloc[index, 4:7].head())\n",
    "        \n",
    "        df.update(new_df)\n",
    "        print(\"----------------------------------------------------------\")\n",
    "        print(\"RESULT AFTERT\")\n",
    "        print(df.iloc[index, 4:7].head())\n",
    "    result['nachher'] = df[column]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " #Standard Error of the regression estimates is equal to std() of the errors of each estimates\n",
    "    predict = model.predict(df[parameters])\n",
    "    std_error = (predict[df[feature].notnull()] - df.loc[df[feature].notnull(), feature + '_imp']).std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#observe that I preserve the index of the missing data from the original dataframe\n",
    "    random_predict = np.random.normal(size = df[feature].shape[0], \n",
    "                                      loc = predict, \n",
    "                                      scale = std_error)\n",
    "    random_data.loc[(df[feature].isnull()) & (random_predict > 0), \"Ran\" + feature] = random_predict[(df[feature].isnull()) & \n",
    "                                                                            (random_predict > 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set()\n",
    "fig, axes = plt.subplots(nrows = 2, ncols = 2)\n",
    "fig.set_size_inches(8, 8)\n",
    "\n",
    "for index, variable in enumerate([\"Insulin\", \"SkinThickness\"]):\n",
    "    sns.distplot(df[variable].dropna(), kde = False, ax = axes[index, 0])\n",
    "    sns.distplot(random_data[\"Ran\" + variable], kde = False, ax = axes[index, 0], color = 'red')\n",
    "    axes[index, 0].set(xlabel = variable + \" / \" + variable + '_imp')\n",
    "    \n",
    "    sns.boxplot(data = pd.concat([df[variable], random_data[\"Ran\" + variable]], axis = 1),\n",
    "                ax = axes[index, 1])\n",
    "    \n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    result = df_original[[column,col_corr]]\n",
    "    result['col_corr'] = df[col_corr]\n",
    "    result['vorher'] = df[column]\n",
    "        temp = df[df[col_corr] == v][column].dropna()\n",
    "        med = temp.median()\n",
    "        m = df[col_corr] == v\n",
    "        df.where(m, df[column].fillna(med, inplace=True))\n",
    "        #print(col_corr)\n",
    "        #temp = df[df[col_corr] == v][column].dropna()\n",
    "        #med = temp.median()\n",
    "        #new_df = df[df[col_corr] == v ]\n",
    "        #print(new_df[column].count())\n",
    "        #print(df[column].count())\n",
    "        #new_df.fillna(med, inplace=True)\n",
    "        #print(new_df[column].count())\n",
    "        #df.update(new_df)\n",
    "        #print(df[column].count())\n",
    "        #print(\"LASSSSSSSSSSSSSSSSSSSSSSSSSS\")\n",
    "        #df[df[col_corr] == v & df[column].isna() ][column] = median\n",
    "        #print(df[df[col_corr] == v][column].fillna(\"Lasse\", inplace=True)  )  \n",
    "        #print(df[df[col_corr] == v][column].fillna(df[df[col_corr] == v].median()[column], inplace=True)  )  \n",
    "    result['nachher'] = df[column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imputation(df,column,col_corr):\n",
    "    s = df[col_corr].drop_duplicates().dropna()\n",
    "    for i, v in s.items():\n",
    "        print(type(v))\n",
    "        print(pd.isna(v))\n",
    "        pos = df[col_corr] == v\n",
    "        df_new = df.loc[pos,:]\n",
    "        med = df_new[column].median()\n",
    "        print(med)\n",
    "        print(df_new.head())\n",
    "        df_new[column].fillna(med,  inplace=True)\n",
    "        print(df_new.head())\n",
    "        df.update(df_new)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imputation(df,column,col_corr):\n",
    "    s = df[col_corr].drop_duplicates()\n",
    "    print(s.dtypes)\n",
    "    for i, v in s.items():\n",
    "        print(type(v))\n",
    "        print(pd.isna(v))\n",
    "        if pd.isna(v):\n",
    "            #temp = df[df[col_corr].isna()][column].dropna()\n",
    "            #med = temp.median()\n",
    "            #new_df = df[df[col_corr].isna()]\n",
    "            new_df[column].fillna(new_df[column].median(), inplace=True)\n",
    "            \n",
    "        else:\n",
    "            temp = df[df[col_corr] == v][column].dropna()\n",
    "            med = temp.median()\n",
    "            new_df = df[df[col_corr] == v ]\n",
    "            new_df[column].fillna(med, inplace=True)\n",
    "             \n",
    "        df.update(new_df)\n",
    "    return df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
