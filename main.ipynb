{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1124,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import variablen as var\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from string import ascii_uppercase\n",
    "import seaborn as sns; sns.set()\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = var.dataset_name_1\n",
    "csv_file     = var.original_df_1\n",
    "save_dir = var.prepair_df_dir\n",
    "column = 'AMT_INCOME_TOTAL'\n",
    "result_dir = var.result_dir\n",
    "statistics_dir = var.statistics_dir\n",
    "result_file = 'result'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(csv_file,filename, column, save_dir):\n",
    "    df = pd.read_csv(csv_file)\n",
    "    df = df.dropna() \n",
    "    y = df.loc[:, [column]].values\n",
    "    #y = df.pop(column).to_numpy()\n",
    "    df = df.drop(columns=[column])\n",
    "    X = df.loc[: , df.columns].values\n",
    "    #  X = df.to_numpy()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "    \n",
    "    X_train = pd.DataFrame(X_train, columns= df.columns)\n",
    "    X_test  = pd.DataFrame(X_test,  columns= df.columns)\n",
    "    y_train = pd.DataFrame(y_train, columns= [column])\n",
    "    y_test  = pd.DataFrame(y_test,  columns= [column])\n",
    "    \n",
    "    X_train.to_csv( save_dir  + column + '/X_train_' + filename + '.csv'  ,index=False,sep=';', decimal=',')\n",
    "    X_test.to_csv(  save_dir  + column + '/X_test_'  + filename + '.csv'  ,index=False,sep=';', decimal=',')\n",
    "    y_train.to_csv( save_dir  + column + '/y_train_' + filename + '.csv'  ,index=False,sep=';', decimal=',')\n",
    "    y_test.to_csv(  save_dir  + column + '/y_test_'  + filename + '.csv'  ,index=False,sep=';', decimal=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "split_data(csv_file,filename, column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quelle https://rmisstastic.netlify.app/how-to/python/generate_html/how%20to%20generate%20missing%20values\n",
    "def ampute_mcar(X_complete, missing_rate):\n",
    "    # Mask completly at random some values\n",
    "    M = np.random.binomial(1, missing_rate, size = X_complete.shape)\n",
    "    X_obs = X_complete.copy()\n",
    "    np.putmask(X_obs, M, np.nan)\n",
    "    print('Percentage of newly generated mising values: {}'.\\\n",
    "      #Change Code:     \n",
    "      format(np.round(np.sum(pd.isna(X_obs))/X_obs.size,3)))\n",
    "    \n",
    "    # warning if a full row is missing\n",
    "    for row in X_obs:\n",
    "        if np.all(pd.isna(row)):\n",
    "            warnings.warn('Some row(s) contains only nan values.')\n",
    "            break\n",
    "\n",
    "    # warning if a full col is missing\n",
    "    for col in X_obs.T:\n",
    "        if np.all(pd.isna(col)):\n",
    "            warnings.warn('Some col(s) contains only nan values.')\n",
    "            break\n",
    "            \n",
    "    return X_obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ampute(column_set):\n",
    "    for column in column_set:\n",
    "        for s in var.test_set: \n",
    "            X_complete = pd.read_csv(save_dir + column + '/' + s + '.csv' , delimiter=\";\", decimal=\",\")\n",
    "            for missing_rate in var.missing_rats:\n",
    "                X_obs_mcar =  pd.DataFrame(ampute_mcar(X_complete.to_numpy(), missing_rate))\n",
    "                X_obs_mcar.columns = [X_complete.columns]\n",
    "                filename = str(np.int_(100 * missing_rate))\n",
    "                X_obs_mcar.to_csv(save_dir + column + '/' + s + '/' + filename + \".csv\" ,index=False,sep=';', decimal=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ampute(var.application_record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def means_impute(column_set):\n",
    "\n",
    "    for column in column_set:\n",
    "        X_train = pd.read_csv(save_dir + column + '/' + var.x_train + '.csv' , delimiter=\";\", decimal=\",\")\n",
    "        y_train = pd.read_csv(save_dir + column + '/' + var.y_train + '.csv' , delimiter=\";\", decimal=\",\")\n",
    "        y_test =  pd.read_csv(save_dir + column + '/' + var.y_test  + '.csv' , delimiter=\";\", decimal=\",\")\n",
    "        \n",
    "        wert = y_train[column].mean()\n",
    "        y_files = os.listdir(save_dir + column + '/' + var.y_test + '/' )\n",
    "        results = y_test[[column]].copy()\n",
    "        for i in y_files:\n",
    "            df = pd.read_csv(save_dir + column + '/' + var.y_test + '/' + i , delimiter=\";\", decimal=\",\")\n",
    "            results[i[0:-4]] = df.replace(df,wert)\n",
    "        results.to_csv( result_dir  + var.methode_1 + '/' + column + '.csv'  ,index=False,sep=';', decimal=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mode_impute(column_set):\n",
    "\n",
    "    for column in column_set:\n",
    "        X_train = pd.read_csv(save_dir + column + '/' + var.x_train + '.csv' , delimiter=\";\", decimal=\",\")\n",
    "        y_train = pd.read_csv(save_dir + column + '/' + var.y_train + '.csv' , delimiter=\";\", decimal=\",\")\n",
    "        y_test =  pd.read_csv(save_dir + column + '/' + var.y_test  + '.csv' , delimiter=\";\", decimal=\",\")\n",
    "        \n",
    "        wert = y_train[column].mode().iloc[0,]\n",
    "        y_files = os.listdir(save_dir + column + '/' + var.y_test + '/' )\n",
    "        results = y_test[[column]].copy()\n",
    "        for i in y_files:\n",
    "            df = pd.read_csv(save_dir + column + '/' + var.y_test + '/' + i , delimiter=\";\", decimal=\",\")\n",
    "            results[i[0:-4]] = df.replace(df,wert)\n",
    "        results.to_csv( result_dir  + var.methode_2 + '/' + column + '.csv'  ,index=False,sep=';', decimal=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def median_impute(column_set):\n",
    "\n",
    "    for column in column_set:\n",
    "        X_train = pd.read_csv(save_dir + column + '/' + var.x_train + '.csv' , delimiter=\";\", decimal=\",\")\n",
    "        y_train = pd.read_csv(save_dir + column + '/' + var.y_train + '.csv' , delimiter=\";\", decimal=\",\")\n",
    "        y_test =  pd.read_csv(save_dir + column + '/' + var.y_test  + '.csv' , delimiter=\";\", decimal=\",\")\n",
    "        \n",
    "        wert = y_train[column].median()\n",
    "        y_files = os.listdir(save_dir + column + '/' + var.y_test + '/' )\n",
    "        results = y_test[[column]].copy()\n",
    "        for i in y_files:\n",
    "            df = pd.read_csv(save_dir + column + '/' + var.y_test + '/' + i , delimiter=\";\", decimal=\",\")\n",
    "            results[i[0:-4]] = df.replace(df,wert)\n",
    "        results.to_csv( result_dir  + var.methode_3 + '/' + column + '.csv'  ,index=False,sep=';', decimal=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1026,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(df,trans_df):\n",
    "    for column in df.columns:\n",
    "        changed = pd.Series(data=-1, index=range(df[column].size))\n",
    "        \n",
    "        for i, v in trans_df.iterrows():\n",
    "            change = df[column].ne(v[column])\n",
    "            df[column] = df[column].where(change, i)\n",
    "            changed = changed.where(change,1)\n",
    "        change = changed.ne(-1)\n",
    "        df[column] = df[column].where(change, -1)\n",
    "        df[column] = df[column].astype('float64')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retransform(df,trans_df, types):\n",
    "    for column in df.columns:\n",
    "        \n",
    "        for i, v in trans_df.iterrows():\n",
    "            change = df[column].ne(i)\n",
    "            df[column] = df[column].where(change,v[column])\n",
    "        change = df[column].ne(-1)\n",
    "        df[column] = df[column].astype(types.loc[column])\n",
    "        df[column] = df[column].where(change, np.nan)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame(np.random.randint(100, size=(5, 5)), columns = list(\"ABCDE\"), \n",
    "        s = df[[column]].sort_values(by=column, ascending=True).drop_duplicates(ignore_index=True)\n",
    "        s = s.as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 890,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_trans_table(df):\n",
    "    result = pd.DataFrame()\n",
    "    for column in df.columns:\n",
    "        s = df[[column]].sort_values(by=column, ascending=True).drop_duplicates(ignore_index=True)\n",
    "        result = pd.concat([result,s], axis=1)\n",
    "            \n",
    "        #s = df[[column]]\n",
    "        #s.to_csv(var.prepair_df_dir + col + '/columns/' + column  ,index=False,sep=';', decimal=',',  float_format='%.2f')\n",
    "        #s = pd.read_csv(var.prepair_df_dir  + col + '/columns/' + column , delimiter=\";\", decimal=\",\")\n",
    "        #result[column] = s[column]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation(dataset,column):\n",
    "    print(type(column))\n",
    "    print(column)\n",
    "    corr = dataset.corrwith(column)\n",
    "    print(corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 662,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation(df,column):\n",
    "    corr = df.corr().abs().unstack(level=0)\n",
    "    result = corr[column].drop(index=column)\n",
    "    return result.idxmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(corr[column].max(level=0))\n",
    "    kot = corr[corr>=.9]\n",
    "    plt.figure(figsize=(12,8))\n",
    "    sns.heatmap(kot, cmap=\"Greens\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_redundant_pairs(df):\n",
    "    '''Get diagonal and lower triangular pairs of correlation matrix'''\n",
    "    pairs_to_drop = set()\n",
    "    cols = df.columns\n",
    "    for i in range(0, df.shape[1]):\n",
    "        for j in range(0, i+1):\n",
    "            pairs_to_drop.add((cols[i], cols[j]))\n",
    "    return pairs_to_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_abs_correlations(df, n=5):\n",
    "    au_corr = df.corr().abs().unstack()\n",
    "    labels_to_drop = get_redundant_pairs(df)\n",
    "    au_corr = au_corr.drop(labels=labels_to_drop).sort_values(ascending=False)\n",
    "    return au_corr[0:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation_1_impute(column_set):\n",
    "    for column in column_set:\n",
    "        X_train = pd.read_csv(save_dir + column + '/' + var.x_train + '.csv' , delimiter=\";\", decimal=\",\")\n",
    "        y_train = pd.read_csv(save_dir + column + '/' + var.y_train + '.csv' , delimiter=\";\", decimal=\",\")\n",
    "        y_test =  pd.read_csv(save_dir + column + '/' + var.y_test  + '.csv' , delimiter=\";\", decimal=\",\")\n",
    "        \n",
    "        df = X_train.copy()\n",
    "        df[y_train.columns] = y_train\n",
    "        df =  df.drop(columns=['ID'])\n",
    "\n",
    "        trans_df = create_trans_table(df)\n",
    "        types = df.dtypes \n",
    "        df_temp = transform(df.copy(), trans_df )\n",
    "        #############################################\n",
    "        col_corr = correlation(df_temp ,y_train.columns[0])\n",
    "        # modi_df DF mit Ziel und Corr Spalte\n",
    "        modi_df = df_temp[[col_corr]] \n",
    "        modi_df[y_train.columns[0]] = df[y_train.columns[0]]\n",
    "        modi_df = modi_df.groupby(col_corr)[[y_train.columns[0]]].median()\n",
    "        # hinzuf√ºgen Missing Bedingung\n",
    "        df2 =pd.DataFrame([[np.nan, np.nan]], columns=[col_corr, y_train.columns[0]])\n",
    "        modi_df = modi_df.append(df2, ignore_index=True)\n",
    "        \n",
    "        y_files = os.listdir(save_dir + column + '/' + var.y_test + '/' )\n",
    "        results = y_test[[column]].copy()\n",
    "        \n",
    "        for i in y_files:\n",
    "            df_y = pd.read_csv(save_dir + column + '/' + var.y_test + '/' + i , delimiter=\";\", decimal=\",\")\n",
    "            df_x = pd.read_csv(save_dir + column + '/' + var.x_test + '/' + i , delimiter=\";\", decimal=\",\")\n",
    "             \n",
    "            df_x = df_x.drop(columns=['ID'])  \n",
    "            x_test = transform(df_x, trans_df )\n",
    "\n",
    "            for i, v in modi_df.iterrows():\n",
    "                change = x_test[col_corr].ne(v[col_corr])\n",
    "                y_test[column] = y_test[column].where(change,v[column])\n",
    "                results[i[0:-4]] = retransform(y_test, trans_df, types)\n",
    "        results.to_csv( result_dir  + var.methode_4 + '/' + column + '.csv'  ,index=False,sep=';', decimal=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "correlation_1_impute(var.application_record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rondom_forest_classification_impute(column_set):\n",
    "    for column in column_set:\n",
    "        X_train = pd.read_csv(save_dir + column + '/' + var.x_train + '.csv' , delimiter=\";\", decimal=\",\")\n",
    "        y_train = pd.read_csv(save_dir + column + '/' + var.y_train + '.csv' , delimiter=\";\", decimal=\",\")\n",
    "        y_test =  pd.read_csv(save_dir + column + '/' + var.y_test  + '.csv' , delimiter=\";\", decimal=\",\")\n",
    "        \n",
    "        X_train = X_train.drop(columns=['ID'])\n",
    "        df = X_train.copy()\n",
    "        df[y_train.columns] = y_train\n",
    "        trans_df = create_trans_table(df)\n",
    "        types = df.dtypes \n",
    "        x_temp = transform(X_train.copy(), trans_df )\n",
    "        y_temp = transform(y_train.copy(), trans_df )\n",
    "        ##############################################\n",
    "        sc = StandardScaler()\n",
    "        x_temp = sc.fit_transform(x_temp)\n",
    "        x_temp_test = sc.transform(x_temp)\n",
    "        #############################################\n",
    "        best_tree = -1\n",
    "        best_mean_squared_error = -1\n",
    "        ##############################################\n",
    "        #for i in [40,50,60,70,80,90,100,110,120,130,140,150,160,170]:\n",
    "        for i in [110]:\n",
    "            ###################################\n",
    "            classifier = RandomForestClassifier(n_estimators=i, random_state=0)\n",
    "            classifier.fit(x_temp, y_temp.ravel())\n",
    "            y_pred = classifier.predict(x_temp_test)\n",
    "            ###################################\n",
    "            new_mean_squared_error = metrics.mean_squared_error(y_temp, y_pred)\n",
    "            print(str(i) + \" durch\")\n",
    "            if best_tree == -1 or new_mean_squared_error < best_mean_squared_error:\n",
    "                best_mean_squared_error = new_mean_squared_error\n",
    "                best_tree = i \n",
    "                print(best_tree)\n",
    "                print(best_mean_squared_error)\n",
    "                print(\"Best Tree \" + str(best_tree))\n",
    "        \n",
    "        classifier = RandomForestClassifier(n_estimators=best_tree, random_state=0)\n",
    "        classifier.fit(x_temp, y_temp.ravel())\n",
    "        ######################################\n",
    "        ######################################\n",
    "        results = y_test[[column]].copy()\n",
    "        y_files = os.listdir(save_dir + column + '/' + var.y_test + '/' )\n",
    "        for i in y_files:\n",
    "            df_y = pd.read_csv(save_dir + column + '/' + var.y_test + '/' + i , delimiter=\";\", decimal=\",\")\n",
    "            df_x = pd.read_csv(save_dir + column + '/' + var.x_test + '/' + i , delimiter=\";\", decimal=\",\")\n",
    "            \n",
    "            df_x = df_x.drop(columns=['ID'])\n",
    "            x_test = transform(df_x, trans_df )\n",
    "            X_test = sc.transform(x_test)\n",
    "            y_pred =  classifier.predict(X_test)\n",
    "            y_test = y_pred\n",
    "            results[i[0:-4]] = retransform(y_test, trans_df, types)\n",
    "        results.to_csv( result_dir  + var.methode_7 + '/' + column + '.csv'  ,index=False,sep=';', decimal=',')      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rondom_forest_classification_impute(var.application_record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rondom_forest_regression_impute(column_set):\n",
    "    for column in column_set:\n",
    "        X_train = pd.read_csv(save_dir + column + '/' + var.x_train + '.csv' , delimiter=\";\", decimal=\",\")\n",
    "        y_train = pd.read_csv(save_dir + column + '/' + var.y_train + '.csv' , delimiter=\";\", decimal=\",\")\n",
    "        y_test =  pd.read_csv(save_dir + column + '/' + var.y_test  + '.csv' , delimiter=\";\", decimal=\",\")\n",
    "        \n",
    "        X_train = X_train.drop(columns=['ID'])\n",
    "        df = X_train.copy()\n",
    "        df[y_train.columns] = y_train\n",
    "        trans_df = create_trans_table(df)\n",
    "        types = df.dtypes \n",
    "        x_temp = transform(X_train.copy(), trans_df )\n",
    "        y_temp = transform(y_train.copy(), trans_df )\n",
    "        ##############################################\n",
    "        sc = StandardScaler()\n",
    "        x_temp = sc.fit_transform(x_temp)\n",
    "        x_temp_test = sc.transform(x_temp)\n",
    "        #############################################\n",
    "        best_tree = -1\n",
    "        best_mean_squared_error = -1\n",
    "        ##############################################\n",
    "        #for i in [40,50,60,70,80,90,100,110,120,130,140,150,160,170]:\n",
    "        for i in [110]:\n",
    "            ###################################\n",
    "            classifier = RandomForestClassifier(n_estimators=i, random_state=0)\n",
    "            classifier.fit(x_temp, y_temp.ravel())\n",
    "            y_pred = classifier.predict(x_temp_test)\n",
    "            ###################################\n",
    "            new_mean_squared_error = metrics.mean_squared_error(y_temp, y_pred)\n",
    "            print(str(i) + \" durch\")\n",
    "            if best_tree == -1 or new_mean_squared_error < best_mean_squared_error:\n",
    "                best_mean_squared_error = new_mean_squared_error\n",
    "                best_tree = i \n",
    "                print(best_tree)\n",
    "                print(best_mean_squared_error)\n",
    "                print(\"Best Tree \" + str(best_tree))\n",
    "        \n",
    "        classifier = RandomForestClassifier(n_estimators=best_tree, random_state=0)\n",
    "        classifier.fit(x_temp, y_temp.ravel())\n",
    "        ######################################\n",
    "        ######################################\n",
    "        results = y_test[[column]].copy()\n",
    "        y_files = os.listdir(save_dir + column + '/' + var.y_test + '/' )\n",
    "        for i in y_files:\n",
    "            df_y = pd.read_csv(save_dir + column + '/' + var.y_test + '/' + i , delimiter=\";\", decimal=\",\")\n",
    "            df_x = pd.read_csv(save_dir + column + '/' + var.x_test + '/' + i , delimiter=\";\", decimal=\",\")\n",
    "            \n",
    "            df_x = df_x.drop(columns=['ID'])\n",
    "            x_test = transform(df_x, trans_df )\n",
    "            X_test = sc.transform(x_test)\n",
    "            y_pred =  classifier.predict(X_test)\n",
    "            y_test = y_pred\n",
    "            results[i[0:-4]] = retransform(y_test, trans_df, types)\n",
    "        results.to_csv( result_dir  + var.methode_8 + '/' + column + '.csv'  ,index=False,sep=';', decimal=',')      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rondom_forest_regression_impute(var.application_record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "        s = trans_df[col_corr]\n",
    "        for i, v in s.items():\n",
    "            new_df = df[df[col_corr] == i ]\n",
    "            mod = new_df[y_train.columns[0]].mode().iloc[0]\n",
    "            df2 =pd.DataFrame([[i, mod]], columns=list('IM'))\n",
    "            modi_df = modi_df.append(df2)\n",
    "        df2 =pd.DataFrame([[i, mod]], columns=list('IM'))\n",
    "        y_train.columns[0]\n",
    "            \n",
    "            \n",
    "        #Mode gibt eine Serie's wieder\n",
    "        #print(new_df.head())\n",
    "        if not new_df[column].mode().empty:\n",
    "            new_df[column].fillna(new_df[column].mode().iloc[0], inplace=True)       \n",
    "        df.update(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for methode in var.methodes:\n",
    "    files = os.listdir(result_dir + methode+ '/' )\n",
    "    for file in files:\n",
    "        org_column = file[0:-4]\n",
    "        result = pd.read_csv(result_dir + methode+ '/' +  file , delimiter=\";\", decimal=\",\")\n",
    "        if os.path.exists(statistics_dir + 'statistics.csv'):\n",
    "            statistics = pd.read_csv(statistics_dir + 'statistics.csv' , delimiter=\";\", decimal=\",\")\n",
    "        else:\n",
    "            statistics = pd.DataFrame()\n",
    "        statistic = pd.DataFrame()\n",
    "        original = result.loc[: , org_column]\n",
    "        result = result.drop(columns=[org_column])\n",
    "        columns = np.array(['methode','type','column', 'misssing', 'Wert'])\n",
    "\n",
    "        \n",
    "        for column in result.columns:\n",
    "            values = np.array([methode,'mean_absolute_error', org_column])\n",
    "            values = np.append(values, [column])\n",
    "            values = np.append(values , [metrics.mean_absolute_error(original, result[column])])\n",
    "            statistics = pd.DataFrame(np.array([values]), columns=columns).append(statistics, ignore_index=True)\n",
    "\n",
    "        statistics.to_csv(statistics_dir + 'statistics.csv', index=False,sep=';', decimal=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for methode in var.methodes:\n",
    "    files = os.listdir(result_dir + methode+ '/' )\n",
    "    for file in files:\n",
    "        org_column = file[0:-4]\n",
    "        result = pd.read_csv(result_dir + methode+ '/' +  file , delimiter=\";\", decimal=\",\")\n",
    "        if os.path.exists(statistics_dir + 'statistics.csv'):\n",
    "            statistics = pd.read_csv(statistics_dir + 'statistics.csv' , delimiter=\";\", decimal=\",\")\n",
    "\n",
    "        else:\n",
    "            statistics = pd.DataFrame()\n",
    "            \n",
    "        original = result.loc[: , org_column]\n",
    "        result = result.drop(columns=[org_column])\n",
    "        columns = np.array(['methode','type','column', 'misssing', 'Wert'])\n",
    "\n",
    "        \n",
    "\n",
    "        for column in result.columns:\n",
    "            values = np.array([methode,'mean_squared_error', org_column])\n",
    "            values = np.append(values, [column])\n",
    "            values = np.append(values , [metrics.mean_squared_error(original, result[column])])\n",
    "            statistics = pd.DataFrame(np.array([values]), columns=columns).append(statistics, ignore_index=True)\n",
    "\n",
    "        statistics.to_csv(statistics_dir + 'statistics.csv', index=False,sep=';', decimal=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for methode in var.methodes:\n",
    "    files = os.listdir(result_dir + methode+ '/' )\n",
    "    for file in files:\n",
    "        org_column = file[0:-4]\n",
    "        result = pd.read_csv(result_dir + methode+ '/' +  file , delimiter=\";\", decimal=\",\")\n",
    "        if os.path.exists(statistics_dir + 'statistics.csv'):\n",
    "            statistics = pd.read_csv(statistics_dir + 'statistics.csv' , delimiter=\";\", decimal=\",\")\n",
    "        else:\n",
    "            statistics = pd.DataFrame()\n",
    "            \n",
    "        original = result.loc[: , org_column]\n",
    "        result = result.drop(columns=[org_column])\n",
    "        columns = np.array(['methode','type','column', 'misssing', 'Wert'])\n",
    "\n",
    "\n",
    "        for column in result.columns:\n",
    "            values = np.array([methode,'root_mean_squared_error', org_column])\n",
    "            values = np.append(values, [column])\n",
    "            values = np.append(values , [np.sqrt(metrics.mean_squared_error(original, result[column]))])\n",
    "            statistics = pd.DataFrame(np.array([values]), columns=columns).append(statistics, ignore_index=True)\n",
    "        \n",
    "\n",
    "        statistics.to_csv(statistics_dir + 'statistics.csv', index=False,sep=';', decimal=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    A   B   C   D   E\n",
      "0  58  67  94  16  29\n",
      "1  75  67  53  50  69\n",
      "2   1  48  99  73  49\n",
      "3  63  64  53   5  87\n",
      "4   0  54  34  83  18\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(np.random.randint(100, size=(5, 5)), columns = list(\"ABCDE\"), \n",
    "                  index = [i for i in range(5)])\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A    int32\n",
      "B    int32\n",
      "C    int32\n",
      "D    int32\n",
      "E    int32\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1097,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    A   B   C   D   E\n",
      "0  40  18   7   9  18\n",
      "1  62  21  35  21  20\n",
      "2  68  73  37  23  33\n",
      "3  74  88  54  51  45\n",
      "4  97  97  95  87  52\n"
     ]
    }
   ],
   "source": [
    "trans_df = create_trans_table(df)\n",
    "print(trans_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1098,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     A    B     C    D    E\n",
      "0   97   18  54.0   23   45\n",
      "1   68   21  35.0    9   52\n",
      "2   40   73   7.0   87   20\n",
      "3   62   88  37.0   51   33\n",
      "4   74   97  95.0   21   18\n",
      "5  101  102   NaN  104  105\n"
     ]
    }
   ],
   "source": [
    "df2 = pd.DataFrame([[101, 102,np.nan,104,105]], columns=list('ABCDE'))\n",
    "df = df.append(df2, ignore_index=True)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1099,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     A    B    C    D    E\n",
      "0  4.0  0.0  3.0  2.0  3.0\n",
      "1  2.0  1.0  1.0  0.0  4.0\n",
      "2  0.0  2.0  0.0  4.0  1.0\n",
      "3  1.0  3.0  2.0  3.0  2.0\n",
      "4  3.0  4.0  4.0  1.0  0.0\n",
      "5 -1.0 -1.0 -1.0 -1.0 -1.0\n"
     ]
    }
   ],
   "source": [
    "df1 = transform(df.copy(), trans_df )\n",
    "print(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      A     B     C     D     E\n",
      "0  97.0  18.0  54.0  23.0  45.0\n",
      "1  68.0  21.0  35.0   9.0  52.0\n",
      "2  40.0  73.0   7.0  87.0  20.0\n",
      "3  62.0  88.0  37.0  51.0  33.0\n",
      "4  74.0  97.0  95.0  21.0  18.0\n",
      "5   NaN   NaN   NaN   NaN   NaN\n"
     ]
    }
   ],
   "source": [
    "df2 = retransform(df1.copy(), trans_df, df.dtypes)\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A    object\n",
      "B    object\n",
      "C    object\n",
      "D    object\n",
      "E    object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df2.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1112,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df2.convert_dtypes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A    object\n",
      "B    object\n",
      "C    object\n",
      "D    object\n",
      "E    object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df2.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1045,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A      int64\n",
      "B      int64\n",
      "C    float64\n",
      "D      int64\n",
      "E      int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 863,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0   -1\n",
      "1   -1\n",
      "2   -1\n",
      "3   -1\n",
      "4   -1\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "changed = pd.Series(data=-1, index=range(df['A'].size))\n",
    "print(changed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 874,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     True\n",
      "1    False\n",
      "2    False\n",
      "3    False\n",
      "4     True\n",
      "5    False\n",
      "6    False\n",
      "7    False\n",
      "dtype: bool\n"
     ]
    }
   ],
   "source": [
    "v = pd.Series(range(8))\n",
    "\n",
    "\n",
    "change = df['C'].eq(v)\n",
    "print(change)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 817,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   A  B  C  D    E\n",
      "0  2  1  5  4  2.0\n",
      "1  3  3  1  1  1.0\n",
      "2  4  2  5  3  3.0\n",
      "3  0  0  3  2  4.0\n",
      "4  1  4  4  0  0.0\n"
     ]
    }
   ],
   "source": [
    "df['C'] = df['C'].where(change, \"5\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 876,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     A    B    C    D    E  0\n",
      "0  3.0  0.0  0.0  2.0  1.0  0\n",
      "1  0.0  3.0  3.0  0.0  3.0  1\n",
      "2  1.0  1.0  1.0  4.0  2.0  2\n",
      "3  2.0  4.0  2.0  1.0  0.0  3\n",
      "4  4.0  2.0  4.0  3.0  4.0  4\n",
      "5  NaN  NaN  NaN  NaN  NaN  5\n",
      "6  NaN  NaN  NaN  NaN  NaN  6\n",
      "7  NaN  NaN  NaN  NaN  NaN  7\n"
     ]
    }
   ],
   "source": [
    "df = pd.concat([df,v], axis=1)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 853,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index\n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 848,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['A', 'B', 'C', 'D', 'E'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 808,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1\n",
      "1   -1\n",
      "2    1\n",
      "3    1\n",
      "4   -1\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "changed = changed.where(change, 1)\n",
    "print(changed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 809,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = changed.eq(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1024,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float              float64\n",
      "int                  int64\n",
      "datetime    datetime64[ns]\n",
      "string              object\n",
      "dtype: object\n",
      "int64\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({'float': [1.0],\n",
    "                   'int': [1],\n",
    "                   'datetime': [pd.Timestamp('20180310')],\n",
    "                   'string': ['foo']})\n",
    "types = df.dtypes\n",
    "print(types.head())\n",
    "print(types.loc['int'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1086,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0     1   2  3\n",
      "0    <NA> NaN  3\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame([[\"\", pd.NA, np.nan, \"3\"]])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1085,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     object\n",
      "1     object\n",
      "2    float64\n",
      "3     object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1093,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[3].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1094,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "int64\n"
     ]
    }
   ],
   "source": [
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
